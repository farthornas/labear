{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "518dbb12-4466-4405-acdd-97b0f88f0a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install speechbrain==1.0.0\n",
    "# !pip install torch torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "375f7164-40f9-466c-b68e-db27045335ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: audiosegment in /Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/api/.venv/lib/python3.12/site-packages (0.23.0)\n",
      "Requirement already satisfied: pydub in /Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/api/.venv/lib/python3.12/site-packages (from audiosegment) (0.25.1)\n",
      "Requirement already satisfied: webrtcvad in /Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/api/.venv/lib/python3.12/site-packages (from audiosegment) (2.0.10)\n",
      "Requirement already satisfied: numpy in /Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/api/.venv/lib/python3.12/site-packages (from audiosegment) (2.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install librosa \n",
    "#!pip install wonderwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15323714",
   "metadata": {},
   "source": [
    "from pathlib import Path \n",
    "from pydub import AudioSegment\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import IPython.display as display\n",
    "from IPython.display import Audio\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "import torchaudio\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "86dd7742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/api/.venv/lib/python3.12/site-packages/wonderwords/random_word.py:74: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  \"\"\"The RandomWord class encapsulates multiple methods dealing with the\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path \n",
    "from pydub import AudioSegment\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import IPython.display as display\n",
    "from IPython.display import Audio\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "import torchaudio\n",
    "import librosa\n",
    "import librosa.display\n",
    "import wonderwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "933e267c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_0.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_1.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_2.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_3.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_4.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_5.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_6.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_7.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_8.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_9.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_10.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_11.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_12.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_13.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_14.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_15.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_16.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_17.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_18.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_19.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_20.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_21.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_22.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_23.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_24.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_25.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_26.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_27.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_28.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_29.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_30.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_0.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_1.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_2.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_3.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_4.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_5.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_6.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_7.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_8.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_9.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_10.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_11.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_12.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_13.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_14.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_15.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_16.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_17.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_18.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_19.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_20.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_21.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_22.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_23.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_24.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_25.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_26.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_27.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_28.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_29.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_30.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_0.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_1.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_2.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_3.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_4.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_5.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_6.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_7.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_8.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_9.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_10.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_11.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_12.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_13.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_14.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_15.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_16.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_17.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_18.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_19.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_20.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_21.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_22.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_23.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_24.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_25.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_26.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_27.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_28.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_29.wav\n",
      "/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_30.wav\n"
     ]
    }
   ],
   "source": [
    "# Run only if you havent already diced up the files\n",
    "\n",
    "import audiosegment\n",
    "\n",
    "states = ['air', 'vac', 'off']\n",
    "\n",
    "path = Path(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/\")\n",
    "files = list(path.glob(\"*\"))\n",
    "\n",
    "for state in states:\n",
    "    file = list((path / state).glob(\"*.m4a\"))[0]\n",
    "    audio = audiosegment.from_file(file).dice(4)\n",
    "    for numb, aud in enumerate(audio):\n",
    "        name = f\"{state}_{numb}.wav\"\n",
    "        dirs = path / state / name\n",
    "        print(dirs)\n",
    "        aud.export(dirs , format='wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db74c881-3839-44fd-b947-191c98ba0fa5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Inspect training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8d6180ac-441c-40bc-bef7-eb9837419cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['air', 'vac', 'off']\n",
    "files_path = \"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei\"\n",
    "#files_path2 = \"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/g28\"\n",
    "\n",
    "path = Path(files_path)\n",
    "#path2 = Path(files_path2)\n",
    "\n",
    "files = []\n",
    "for p in path.rglob(\"*.wav\"):\n",
    "    files.append(str(p))\n",
    "    #files += glob.glob(f\"../data/{cls}/*.wav\")\n",
    "#for p in path2.rglob(\"*.wav\"):\n",
    "#    files.append(str(p))\n",
    "#    #files += glob.glob(f\"../data/{cls}/*.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6423dcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_54.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_40.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_41.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_55.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_43.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_57.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_56.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_42.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_46.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_52.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_53.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_47.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_8.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_51.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_45.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_44.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_50.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_9.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_37.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_23.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_22.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_36.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_20.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_34.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_35.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_21.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_25.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_31.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_19.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_18.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_30.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_24.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_32.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_26.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_27.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_33.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_16.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_17.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_29.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_15.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_14.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_28.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_10.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_38.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_39.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_11.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_13.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_12.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_4.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_49.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_61.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_60.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_48.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_5.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_7.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_6.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_2.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_3.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_1.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_58.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_59.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_0.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_37.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_23.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_7.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_6.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_22.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_36.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_20.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_34.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_4.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_5.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_35.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_21.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_19.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_25.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_31.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_1.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_0.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_30.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_24.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_18.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_32.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_26.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_2.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_3.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_27.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_33.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_54.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_40.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_41.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_55.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_43.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_57.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_56.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_42.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_46.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_52.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_53.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_47.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_51.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_45.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_44.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_50.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_61.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_49.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_48.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_60.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_58.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_59.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_16.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_17.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_15.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_29.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_28.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_14.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_38.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_10.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_8.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_9.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_11.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_39.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_13.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/vac/vac_12.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_26.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_32.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_33.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_27.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_31.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_25.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_19.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_18.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_24.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_30.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_34.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_20.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_21.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_35.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_23.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_37.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_36.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_22.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_45.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_51.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_7.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_6.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_50.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_44.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_52.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_46.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_4.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_5.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_47.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_53.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_57.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_43.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_1.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_0.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_42.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_56.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_40.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_54.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_2.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_3.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_55.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_41.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_58.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_59.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_8.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_9.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_49.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_61.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_60.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_48.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_13.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_12.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_10.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_38.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_39.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_11.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_29.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_15.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_14.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_28.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_16.wav', '/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/off/off_17.wav']\n"
     ]
    }
   ],
   "source": [
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b8c6dd63-ec9a-486b-9aa0-ea862701f6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>/Users/jonas/Library/CloudStorage/OneDrive-Uni...</td>\n",
       "      <td>air</td>\n",
       "      <td>air_37.wav</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>/Users/jonas/Library/CloudStorage/OneDrive-Uni...</td>\n",
       "      <td>off</td>\n",
       "      <td>off_48.wav</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>/Users/jonas/Library/CloudStorage/OneDrive-Uni...</td>\n",
       "      <td>air</td>\n",
       "      <td>air_45.wav</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>/Users/jonas/Library/CloudStorage/OneDrive-Uni...</td>\n",
       "      <td>vac</td>\n",
       "      <td>vac_32.wav</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>/Users/jonas/Library/CloudStorage/OneDrive-Uni...</td>\n",
       "      <td>vac</td>\n",
       "      <td>vac_16.wav</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filepath label        name  \\\n",
       "18   /Users/jonas/Library/CloudStorage/OneDrive-Uni...   air  air_37.wav   \n",
       "173  /Users/jonas/Library/CloudStorage/OneDrive-Uni...   off  off_48.wav   \n",
       "14   /Users/jonas/Library/CloudStorage/OneDrive-Uni...   air  air_45.wav   \n",
       "82   /Users/jonas/Library/CloudStorage/OneDrive-Uni...   vac  vac_32.wav   \n",
       "110  /Users/jonas/Library/CloudStorage/OneDrive-Uni...   vac  vac_16.wav   \n",
       "\n",
       "     duration  \n",
       "18        4.0  \n",
       "173       4.0  \n",
       "14        4.0  \n",
       "82        4.0  \n",
       "110       4.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dict(filepath=files))\n",
    "df[\"label\"] = df.filepath.apply(lambda x: Path(x).parent.name)\n",
    "df[\"name\"] = df.filepath.apply(lambda x: Path(x).name)\n",
    "df[\"duration\"] = df.filepath.apply(lambda x: librosa.get_duration(path=x))\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3e336f4e-6aca-4261-9070-ef8db382ed3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "duration\n",
       "4.0    180\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop samples that are to short in duration (< 3.5 secs)\n",
    "df = df.drop(df[(df.duration < 3.99)].index)\n",
    "df.duration.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e25783d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the first sample in all categories\n",
    "# as first sample often has silence in it\n",
    "#df_0 = df[df.name.str.contains(\"_0.wav\")]\n",
    "df = df[~df.name.str.contains(\"_0.wav\")]\n",
    "df = df[~df.name.str.contains(\"_31.wav\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "edf66cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "air    58\n",
       "vac    58\n",
       "off    58\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "42278b54-1381-4086-bbdc-153bd51b6515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_of(cls: str, random_state=None):\n",
    "    return df[df.label == cls].sample(random_state=random_state).iloc[0]\n",
    "    \n",
    "def play_sample(sample):\n",
    "    print(sample.filepath, sample.label)\n",
    "    return display.Audio(sample.filepath, autoplay=True)\n",
    "\n",
    "def play_sample_of(cls: str, random_state=None):\n",
    "    sample = get_sample_of(cls, random_state)\n",
    "    return play_sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "67ad43ae-7a10-45ab-9d44-b2ed7b66834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(filepath, title=None):\n",
    "    y, sr = librosa.load(filepath)\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(S_dB, x_axis='time', y_axis='mel', sr=sr, fmax=8000)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f'Mel-frequency spectrogram ({title})')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def show_sample(sample, **kwargs):\n",
    "    plot_spectrogram(sample.filepath, **kwargs)\n",
    "\n",
    "def show_sample_of(cls: str, random_state=None):\n",
    "    sample = get_sample_of(cls, random_state)\n",
    "    return show_sample(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1cb028-546a-405c-b183-414027ca634f",
   "metadata": {},
   "source": [
    "## Train/validation split\n",
    "\n",
    "Split data into training and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ccc5f4b0-5ef9-4560-a4d2-0687bde34dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2070c83a-ce72-4d72-ace4-7ef4a3a59a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((139, 4), (35, 4))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, val = train_test_split(df, stratify=df.label, random_state=0, test_size=0.20)\n",
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "77119351-a85d-4a42-82b0-ff349120b7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['isval'] = [i in val.index for i in df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d317fff1-9507-4f0c-96bd-b35dd65c833b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isval\n",
       "False    139\n",
       "True      35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isval.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a274f2d7-a99c-455d-9ced-3ddedee8ee21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "vac    47\n",
       "air    46\n",
       "off    46\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "771d4e08-234c-4e2a-aece-0215b7292561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105    vac_49.wav\n",
       "6      air_56.wav\n",
       "129    off_25.wav\n",
       "19     air_23.wav\n",
       "180    off_29.wav\n",
       "88     vac_54.wav\n",
       "109    vac_59.wav\n",
       "23     air_34.wav\n",
       "75     vac_25.wav\n",
       "9      air_52.wav\n",
       "62     vac_37.wav\n",
       "71      vac_5.wav\n",
       "3      air_55.wav\n",
       "72     vac_35.wav\n",
       "158    off_42.wav\n",
       "56      air_2.wav\n",
       "130    off_19.wav\n",
       "169     off_9.wav\n",
       "41     air_28.wav\n",
       "163     off_3.wav\n",
       "116    vac_38.wav\n",
       "114    vac_28.wav\n",
       "168     off_8.wav\n",
       "58      air_1.wav\n",
       "167    off_59.wav\n",
       "38     air_29.wav\n",
       "165    off_41.wav\n",
       "64      vac_7.wav\n",
       "21     air_36.wav\n",
       "0      air_54.wav\n",
       "141    off_22.wav\n",
       "86     vac_27.wav\n",
       "181    off_15.wav\n",
       "24     air_35.wav\n",
       "143    off_51.wav\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea5e100-6db8-488c-baed-74efc6492845",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Import / download pretrained model (speechbrain urbansound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "27ae1a98-1898-451b-b19d-f2174d986c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog_bark']\n"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "from speechbrain.inference.classifiers import EncoderClassifier\n",
    "classifier = EncoderClassifier.from_hparams(source=\"speechbrain/urbansound8k_ecapa\", savedir=\"models/gurbansound8k_ecapa\")\n",
    "out_prob, score, index, text_lab = classifier.classify_file('speechbrain/urbansound8k_ecapa/dog_bark.wav')\n",
    "print(text_lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c607d70",
   "metadata": {},
   "source": [
    "# Check that our files are compatible with the downloaded classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "41c989ee-139c-4b58-a2d0-638700a0b35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2448, -0.2221,  0.4067, -0.4413, -0.0444, -0.1651,  0.5004,  0.3076,\n",
       "           0.1879, -0.1033]]),\n",
       " tensor([0.5004]),\n",
       " tensor([6]),\n",
       " ['engine_idling'])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "rand = random.randint(0,(len(cats) - 1))\n",
    "sample = get_sample_of(cats[rand], random_state=1)\n",
    "classifier.classify_file(sample.filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348e937b-16c7-49f5-bc51-dbdeff6587ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Convert audio to tensors for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2bb72294-59a9-47fb-bc4f-54fa3c2cff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c301e06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_54.wav'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7f4ee2-4675-4298-be99-d78dde51cce2",
   "metadata": {},
   "source": [
    "different samples have different length tensor (longer or shorter time series) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c2712ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "import numpy as np\n",
    "from torchaudio import transforms\n",
    "from torchaudio.io import AudioEffector\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class AudioUtil():\n",
    "    #---------------\n",
    "    # Load an audio file. Return the signal as a tensor and the sample rate\n",
    "    #---------------\n",
    "    @staticmethod\n",
    "    def open(audio_file):\n",
    "        sig, sr = torchaudio.load(audio_file)\n",
    "        \n",
    "        return (sig, sr)\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_gain(aud, sig_max=0.9):\n",
    "        sig, sr = aud\n",
    "        gn = sig_max / sig.max()\n",
    "\n",
    "        transform = transforms.Vol(gain=gn, gain_type=\"amplitude\")\n",
    "        \n",
    "        sig_amp = transform(sig)\n",
    "        \n",
    "        return (sig_amp, sr)\n",
    "    \n",
    "    #---------------\n",
    "    # Convert soundfile to desired number of channels\n",
    "    #---------------\n",
    "    @staticmethod\n",
    "    def rechannel(aud, new_channel):\n",
    "        \n",
    "        sig, sr = aud\n",
    "        \n",
    "        if sig.shape[0] == new_channel:\n",
    "            #Nothing todo\n",
    "            return aud\n",
    "        \n",
    "        if (new_channel == 1):\n",
    "            #Convert stereo to mono by selecting only the first channel\n",
    "            resig = sig[:1, :]\n",
    "        else:\n",
    "            #Convert from mono to sterio by duplicating the first channel\n",
    "            resig = torch.cat([sig,sig])\n",
    "        return ((resig, sr))\n",
    "    \n",
    "    #---------------\n",
    "    #Resample to make sure samplerate is the same for all files - resample applies to one channel at a time\n",
    "    #---------------\n",
    "    @staticmethod\n",
    "    def resample(aud, newsr):\n",
    "        \n",
    "        sig, sr = aud\n",
    "        \n",
    "        if (sr == newsr):\n",
    "            #do nothing\n",
    "            return aud\n",
    "        \n",
    "        num_channels = sig.shape[0]\n",
    "        \n",
    "        #resample first channel\n",
    "        resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1,:])\n",
    "        \n",
    "        if (num_channels > 1):\n",
    "            #Resample the second channel and merge both\n",
    "            retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:,:])\n",
    "            resig = torch.cat([resig, retwo])\n",
    "            \n",
    "        return ((resig, newsr))\n",
    "    \n",
    "    \n",
    "    #-----------------\n",
    "    #Pad or turncate the signal to be off a standard length in milliseconds\n",
    "    #-----------------\n",
    "    @staticmethod\n",
    "    def pad_trunc(aud, max_ms):\n",
    "\n",
    "        sig, sr = aud\n",
    "        num_rows, sig_len = sig.shape\n",
    "        max_len = sr * max_ms / 1000\n",
    "        \n",
    "        if (sig_len > max_len):\n",
    "            #Turncate the signal to the given length\n",
    "            print(f\"Signal length larger than max length {sig_len} > {max_len}\")\n",
    "            sig = sig[:,:max_len]\n",
    "        elif (sig_len < max_len):\n",
    "            print(f\"Signal length smaller than max length {sig_len} < {max_len}\")\n",
    "\n",
    "            pad_begin_len = random.randint(0, max_len - sig_len)\n",
    "            pad_end_len = max_len - sig_len - pad_begin_len\n",
    "            \n",
    "            #pad with zeroes\n",
    "            pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
    "            pad_end = torch.zeros((num_rows, pad_end_len))\n",
    "            \n",
    "            sig = torch.cat((pad_begin, sig, pad_end), 1)\n",
    "        \n",
    "        return (sig, sr)\n",
    "\n",
    "    #--------------------\n",
    "    #Shift the signal by a random bit, end of signal is wrapped around \n",
    "    #to beginning\n",
    "    #--------------------\n",
    "    @staticmethod\n",
    "    def time_shift(aud, shift_limit):\n",
    "        sig, sr = aud\n",
    "        \n",
    "        _, sig_len = sig.shape\n",
    "        shift_amt = int(random.random() * shift_limit * sig_len)\n",
    "        return (sig.roll(shift_amt), sr)\n",
    "\n",
    "    #--------------------\n",
    "    #Add eccho or vibrato to the signal. \n",
    "    #This method is intented for the generation of synthetic data,\n",
    "    #using a limited dataset. \n",
    "    #--------------------\n",
    "    @staticmethod\n",
    "    def add_rand_effect(aud):\n",
    "        sig, sr = aud    \n",
    "        effect = random.randint(0,1)\n",
    "        if effect ==0:\n",
    "            delay = random.randint(40,100)\n",
    "            decay = round(random.uniform(0.2,0.7), 2)\n",
    "            effect = \"aecho=in_gain=0.8:out_gain=0.9:delays={}:decays={}\".format(delay, decay)\n",
    "        elif effect == 1:\n",
    "            freq = random.randint(9,15)\n",
    "            decay = round(random.uniform(0.15,0.4), 2)\n",
    "            effect = \"vibrato=f={}:d={}\".format(freq, decay)\n",
    "        effector = AudioEffector(effect=effect, pad_end=False)\n",
    "        sig_ef = effector.apply(sig.T, int(sr)) # int(sr)\n",
    "        sig_ef = sig_ef.T\n",
    "\n",
    "        return (sig_ef, sr)\n",
    "    \n",
    "    #----------------------------------\n",
    "    #Genetate spectrogram\n",
    "    #----------------------------------\n",
    "    @staticmethod\n",
    "    def spectro_gram(aud, n_mels=64, n_fft=1024, hop_len=None):\n",
    "        sig,sr = aud\n",
    "        top_db = 80\n",
    "        \n",
    "        #spec has shape [channel, n_mels, time]\n",
    "        spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "        \n",
    "        #convert to db\n",
    "        spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "        \n",
    "        return spec\n",
    "    \n",
    "    \n",
    "    #Augment the spectrogram by masking out some sections of it in both the frequency\n",
    "    #dimencion (Horizontal) and the time dimension (vertical bars)\n",
    "    \n",
    "    @staticmethod\n",
    "    def spectro_augment(spec, max_mask_pct=0.1, n_freq_masks=1, n_time_masks=1):\n",
    "        _, n_mels, n_steps = spec.shape\n",
    "        mask_value = spec.mean()\n",
    "        aug_spec = spec\n",
    "        \n",
    "        freq_mask_param = max_mask_pct * n_mels\n",
    "        for _ in range(n_freq_masks):\n",
    "            aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "        \n",
    "        time_mask_param = max_mask_pct * n_steps\n",
    "        for _ in range(n_time_masks):\n",
    "            aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "        \n",
    "        return np.absolute(aug_spec) # Jonas added np.absolute\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cea554cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from speechbrain.dataio.preprocess import AudioNormalizer\n",
    "\n",
    "class LoadTransform():\n",
    "    def __init__(self):\n",
    "        self.duration = 4000\n",
    "        self.sr_classifier = 16000 # this is the required sample rate for the classifier\n",
    "        self.channel = 1\n",
    "        self.shift_pct = 0.3\n",
    "        self.audio_normalizer = AudioNormalizer(sample_rate=self.sr_classifier)\n",
    "    \n",
    "    def load_audio(self, file_path, return_spectrogram=False):\n",
    "        signal = AudioUtil.open(file_path)\n",
    "        #print(f\"Audio tensor shape ={signal[0].shape}\")\n",
    "\n",
    "        signal = AudioUtil.rechannel(signal, self.channel)\n",
    "        #print(f\"rechan tensor shape ={signal[0].shape}\")\n",
    "\n",
    "        signal = AudioUtil.pad_trunc(signal, self.duration)\n",
    "        #print(f\"dur_aud tensor shape ={signal[0].shape}\")\n",
    "\n",
    "        signal = AudioUtil.time_shift(signal, self.shift_pct)\n",
    "        #print(f\"ts_aud tensor shape ={signal[0].shape}\")\n",
    "    \n",
    "        if return_spectrogram:\n",
    "            return AudioUtil.spectro_gram(signal)\n",
    "\n",
    "        signal, sr = signal[0].T, signal[1]\n",
    "        #print(f\"Audio sample rate ={sr}\")\n",
    "\n",
    "\n",
    "        return self.audio_normalizer(signal, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "83280057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "#----------------\n",
    "#Sound dataset\n",
    "#----------------\n",
    "    \n",
    "class SoundDS(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        #self.df = df\n",
    "        #self.data_paths = data_paths\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.duration = 4000\n",
    "        self.sr = 44100\n",
    "        self.channel = 2\n",
    "        self.shift_pct = 0.3\n",
    "    \n",
    "    #------------------\n",
    "    #Number of items in dataset\n",
    "    #------------------\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    #------------------\n",
    "    #Get i'th item in dataset\n",
    "    #------------------\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the class ID  \n",
    "        #class_id = self.df.loc[idx, 'label']\n",
    "        #audio_file = str(self.df.loc[idx, 'filepath'])\n",
    "        audio_file = self.X[idx]\n",
    "        aud = AudioUtil.open(audio_file)\n",
    "        reaud = AudioUtil.resample(aud, self.sr)\n",
    "        rechan = AudioUtil.rechannel(reaud, self.channel)\n",
    "        dur_aud = AudioUtil.pad_trunc(rechan, self.duration)\n",
    "        ts_aud = AudioUtil.time_shift(dur_aud, self.shift_pct)\n",
    "        y = torch.zeros(3)\n",
    "        y[cats.index(self.y[idx])] = 1.\n",
    "        #sgram = AudioUtil.spectro_gram(dur_aud, n_mels=64, n_fft=1024, hop_len=None)\n",
    "        return ts_aud, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158356d3-c2b7-491f-a027-d693883c6e64",
   "metadata": {},
   "source": [
    "the classifier's `load_audio` function does some extra stuff like normalization, so let's use that \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8fc677f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data/g28_huawei/air/air_54.wav'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filep = df.iloc[0].filepath\n",
    "filep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d83dfb9c-27d1-45bd-a1d5-0d846ac88505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier tensor shape = torch.Size([64000])\n",
      "Transfrom tensor shape = torch.Size([64000])\n"
     ]
    }
   ],
   "source": [
    "tens = classifier.load_audio(sample.filepath)\n",
    "Transform = LoadTransform()\n",
    "tens2 = Transform.load_audio(sample.filepath)\n",
    "print(f\"Classifier tensor shape = {tens.shape}\")\n",
    "print(f\"Transfrom tensor shape = {tens2.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fbfdebe9-606e-4203-b98d-52fe04c3ddf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64000])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tens2.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "db9a63fd-465f-4bc1-9e92-61acfec23d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 192])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_length =  torch.tensor([1.])\n",
    "enc = classifier.encode_batch(tens2.unsqueeze(0), rel_length)\n",
    "enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a41a0ea9-01e5-45f7-a135-a3723e718490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2511, -0.2226,  0.4351, -0.4299, -0.0444, -0.1714,  0.4929,  0.3036,\n",
       "          0.1701, -0.0985]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilities of each class\n",
    "preds = classifier.mods.classifier(enc).squeeze(1); preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "de168ba5-2376-41c2-8f30-9a15341e47ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch of preds, but just 1 in the batch \n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "90941511-53c3-4c9c-8ced-f72cb776d984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2448, -0.2221,  0.4067, -0.4413, -0.0444, -0.1651,  0.5004,  0.3076,\n",
       "           0.1879, -0.1033]]),\n",
       " tensor([0.5004]),\n",
       " tensor([6]),\n",
       " ['engine_idling'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that our work agrees with the full implementation \n",
    "classifier.classify_file(str(sample.filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace62738-b25a-4a0e-b999-843f2dd2090b",
   "metadata": {},
   "source": [
    "## Create dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a747206e-986d-4de7-9b4f-4e145e70cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3bc48d3c-719b-4b5d-b851-7717aef3c47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['air', 'vac', 'off']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c8ea7ebf-c071-4b6b-9bd3-d09f18e929ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>/Users/jonas/Library/CloudStorage/OneDrive-Uni...</td>\n",
       "      <td>air</td>\n",
       "      <td>air_14.wav</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/Users/jonas/Library/CloudStorage/OneDrive-Uni...</td>\n",
       "      <td>air</td>\n",
       "      <td>air_47.wav</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>/Users/jonas/Library/CloudStorage/OneDrive-Uni...</td>\n",
       "      <td>off</td>\n",
       "      <td>off_32.wav</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              filepath label        name  \\\n",
       "40   /Users/jonas/Library/CloudStorage/OneDrive-Uni...   air  air_14.wav   \n",
       "11   /Users/jonas/Library/CloudStorage/OneDrive-Uni...   air  air_47.wav   \n",
       "125  /Users/jonas/Library/CloudStorage/OneDrive-Uni...   off  off_32.wav   \n",
       "\n",
       "     duration  \n",
       "40        4.0  \n",
       "11        4.0  \n",
       "125       4.0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8d2e20f5-d386-4370-9a8b-16d1ba8cbcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import cache\n",
    "\n",
    "class ApplianceDS(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y \n",
    "    def __len__(self): return len(self.y)\n",
    "    \n",
    "    @cache\n",
    "    def __getitem__(self, i):\n",
    "        y = torch.zeros(len(cats))\n",
    "        y[cats.index(self.y[i])] = 1.\n",
    "        return self.X[i], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c1ed94bc-abf6-4048-81f5-cd521f512be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([139, 64000]), torch.Size([35, 64000]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Xtrain = torch.stack([classifier.load_audio(fp) for fp in train.filepath])\n",
    "#Xtrain = torch.stack([classifier.load_audio(fp) for fp in train.filepath])\n",
    "Xtrain = torch.stack([Transform.load_audio(fp) for fp in train.filepath])\n",
    "Xval = torch.stack([Transform.load_audio(fp) for fp in val.filepath])\n",
    "#Xtest = torch.stack([Transform.load_audio(fp) for fp in test.filepath])\n",
    "\n",
    "ytrain = list(train.label)\n",
    "yval = list(val.label)\n",
    "#ytest = list(test.label)\n",
    "Xtrain.shape, Xval.shape\n",
    "\n",
    "\n",
    "# (torch.Size([59, 64000]), torch.Size([13, 64000]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "066e183d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vac',\n",
       " 'air',\n",
       " 'off',\n",
       " 'air',\n",
       " 'off',\n",
       " 'vac',\n",
       " 'vac',\n",
       " 'air',\n",
       " 'vac',\n",
       " 'air',\n",
       " 'vac',\n",
       " 'vac',\n",
       " 'air',\n",
       " 'vac',\n",
       " 'off',\n",
       " 'air',\n",
       " 'off',\n",
       " 'off',\n",
       " 'air',\n",
       " 'off',\n",
       " 'vac',\n",
       " 'vac',\n",
       " 'off',\n",
       " 'air',\n",
       " 'off',\n",
       " 'air',\n",
       " 'off',\n",
       " 'vac',\n",
       " 'air',\n",
       " 'air',\n",
       " 'off',\n",
       " 'vac',\n",
       " 'off',\n",
       " 'air',\n",
       " 'off']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ec66f0ba-8b7b-49ad-8d45-080ff254c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ApplianceDS(Xtrain, ytrain)\n",
    "val_ds = ApplianceDS(Xval, yval)\n",
    "#test_ds = ApplianceDS(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7bed9fe4-1855-4cd6-9932-ffb474d144e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "# we don't need batches for the validation set so just put into a big batch \n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=8, shuffle=True)\n",
    "#test_dl = torch.utils.data.DataLoader(test_ds, batch_size=len(test_ds), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a56a718c-6710-4e09-be35-66cc8c12c7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 64000]), torch.Size([8, 3]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xval, yval = next(iter(val_dl))\n",
    "Xval.shape, yval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "735317d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights():\n",
    "    classifier.mods.classifier.weight = torch.nn.Parameter(torch.FloatTensor(len(cats), 192))\n",
    "    torch.nn.init.xavier_uniform_(classifier.mods.classifier.weight)\n",
    "reset_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a310d9f7-d007-41f1-a717-18abab7dec56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "for param in classifier.mods.classifier.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0a2cf1ee-167b-4824-87a6-4cd4e1bec357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fbank(\n",
       "  (compute_STFT): STFT()\n",
       "  (compute_fbanks): Filterbank()\n",
       "  (compute_deltas): Deltas()\n",
       "  (context_window): ContextWindow()\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.mods.compute_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6dac0339-f586-4f66-925d-540af1ed5b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_features\n",
      "mean_var_norm\n",
      "embedding_model\n",
      "embedding_model False\n",
      "classifier\n",
      "classifier True\n"
     ]
    }
   ],
   "source": [
    "for mod in classifier.mods:\n",
    "    print(mod)\n",
    "    for p in classifier.mods.__getattr__(mod).parameters():\n",
    "        print(mod, p.requires_grad)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6a96b8de-0ed2-4088-8f92-669771ea7d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6f500f-6d2a-41da-8e76-bca22eb9a408",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\"\"\"\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "reset_weights()\n",
    "optimizer = torch.optim.Adam(classifier.mods.classifier.parameters(), lr=0.002) # changed from 0.001\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10)\n",
    "for epoch in tqdm(range(100)):\n",
    "    losses = []\n",
    "    for batch_idx, (X, y) in enumerate(train_dl):\n",
    "        logits, confidences, classes, decoded_classes = classifier(X)\n",
    "        loss = loss_fn(logits, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "    train_loss.append(np.mean(losses))\n",
    "    \n",
    "    val_preds, *_ = classifier(Xval)    \n",
    "    val_loss_ = loss_fn(val_preds, yval)\n",
    "    scheduler.step(val_loss_)\n",
    "    val_loss.append(val_loss_.item())\n",
    "\n",
    "    print(f\"Epoch {epoch}: Train Loss: {train_loss[-1]:.4f}, Validation Loss: {val_loss[-1]:.4f}, Learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7fa6a70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:05<09:12,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss: 1.0745, Validation Loss: 1.0649\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 2/100 [00:11<09:37,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1.0320, Validation Loss: 1.0057\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 3/100 [00:17<09:48,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.9943, Validation Loss: 0.9488\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 4/100 [00:23<09:24,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.9477, Validation Loss: 0.9122\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 5/100 [00:28<09:03,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.9151, Validation Loss: 0.8731\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 6/100 [00:34<08:37,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.8892, Validation Loss: 0.8384\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 7/100 [00:39<08:16,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.8357, Validation Loss: 0.8089\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 8/100 [00:44<08:09,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.8455, Validation Loss: 0.7775\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 9/100 [00:49<07:56,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.8197, Validation Loss: 0.7538\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 10/100 [00:54<07:52,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.7890, Validation Loss: 0.7462\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 11/100 [01:00<07:50,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.7682, Validation Loss: 0.7230\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 12/100 [01:05<07:42,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.7724, Validation Loss: 0.7095\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 13/100 [01:10<07:33,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss: 0.7280, Validation Loss: 0.6971\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 14/100 [01:15<07:22,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss: 0.7532, Validation Loss: 0.6793\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 15/100 [01:20<07:16,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss: 0.7286, Validation Loss: 0.6732\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 16/100 [01:25<07:09,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss: 0.7146, Validation Loss: 0.6643\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 17/100 [01:30<07:06,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss: 0.7459, Validation Loss: 0.6699\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 18/100 [01:36<07:07,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss: 0.7386, Validation Loss: 0.6613\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 19/100 [01:41<06:59,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss: 0.7001, Validation Loss: 0.6477\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 20/100 [01:46<07:00,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss: 0.6937, Validation Loss: 0.6493\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 21/100 [01:51<06:49,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss: 0.6800, Validation Loss: 0.6467\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 22/100 [01:56<06:45,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss: 0.6899, Validation Loss: 0.6413\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 23/100 [02:01<06:38,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss: 0.6813, Validation Loss: 0.6442\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 24/100 [02:07<06:31,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss: 0.6953, Validation Loss: 0.6500\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 25/100 [02:12<06:22,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss: 0.6948, Validation Loss: 0.6426\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 26/100 [02:17<06:18,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss: 0.6740, Validation Loss: 0.6420\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 27/100 [02:22<06:15,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss: 0.7028, Validation Loss: 0.6443\n",
      "Learning Rate: 0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 28/100 [02:27<06:11,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss: 0.6721, Validation Loss: 0.6434\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 29/100 [02:32<06:03,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss: 0.6847, Validation Loss: 0.6431\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 30/100 [02:38<06:05,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss: 0.6737, Validation Loss: 0.6451\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 31/100 [02:43<06:09,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss: 0.6816, Validation Loss: 0.6315\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 32/100 [02:49<06:06,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss: 0.6799, Validation Loss: 0.6401\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 33/100 [02:54<05:59,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train Loss: 0.6761, Validation Loss: 0.6436\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 34/100 [02:59<05:48,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss: 0.6801, Validation Loss: 0.6399\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 35/100 [03:04<05:38,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss: 0.6800, Validation Loss: 0.6367\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 36/100 [03:09<05:33,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train Loss: 0.6788, Validation Loss: 0.6413\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 37/100 [03:14<05:22,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss: 0.6772, Validation Loss: 0.6300\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 38/100 [03:19<05:17,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Train Loss: 0.6796, Validation Loss: 0.6366\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 39/100 [03:24<05:11,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Train Loss: 0.6921, Validation Loss: 0.6361\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 40/100 [03:30<05:08,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Train Loss: 0.6844, Validation Loss: 0.6317\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 41/100 [03:35<05:02,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Train Loss: 0.6901, Validation Loss: 0.6329\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 42/100 [03:41<05:14,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Train Loss: 0.6867, Validation Loss: 0.6296\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 43/100 [03:47<05:13,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Train Loss: 0.6635, Validation Loss: 0.6384\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 44/100 [03:52<05:04,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Train Loss: 0.6785, Validation Loss: 0.6323\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 45/100 [03:57<04:52,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Train Loss: 0.6620, Validation Loss: 0.6328\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 46/100 [04:02<04:45,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss: 0.7093, Validation Loss: 0.6323\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 47/100 [04:07<04:35,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss: 0.7167, Validation Loss: 0.6368\n",
      "Learning Rate: 9e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 48/100 [04:12<04:27,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss: 0.6857, Validation Loss: 0.6357\n",
      "Learning Rate: 9e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 49/100 [04:17<04:18,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss: 0.7018, Validation Loss: 0.6360\n",
      "Learning Rate: 9e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 50/100 [04:22<04:17,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss: 0.6570, Validation Loss: 0.6344\n",
      "Learning Rate: 9e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 51/100 [04:28<04:16,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss: 0.6833, Validation Loss: 0.6372\n",
      "Learning Rate: 9e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 52/100 [04:33<04:08,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: Train Loss: 0.7145, Validation Loss: 0.6406\n",
      "Learning Rate: 9e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 53/100 [04:38<04:01,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52: Train Loss: 0.6790, Validation Loss: 0.6402\n",
      "Learning Rate: 9e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 54/100 [04:43<03:55,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: Train Loss: 0.6841, Validation Loss: 0.6336\n",
      "Learning Rate: 9.000000000000001e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 55/100 [04:49<03:59,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54: Train Loss: 0.6719, Validation Loss: 0.6354\n",
      "Learning Rate: 9.000000000000001e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 56/100 [04:54<03:50,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55: Train Loss: 0.6801, Validation Loss: 0.6354\n",
      "Learning Rate: 9.000000000000001e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 57/100 [04:59<03:46,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56: Train Loss: 0.6947, Validation Loss: 0.6355\n",
      "Learning Rate: 9.000000000000001e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 58/100 [05:04<03:40,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57: Train Loss: 0.6865, Validation Loss: 0.6379\n",
      "Learning Rate: 9.000000000000001e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 59/100 [05:10<03:36,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: Train Loss: 0.6709, Validation Loss: 0.6372\n",
      "Learning Rate: 9.000000000000001e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 60/100 [05:15<03:30,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59: Train Loss: 0.7016, Validation Loss: 0.6364\n",
      "Learning Rate: 9.000000000000001e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 61/100 [05:20<03:23,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60: Train Loss: 0.6653, Validation Loss: 0.6349\n",
      "Learning Rate: 9.000000000000001e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 62/100 [05:25<03:17,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61: Train Loss: 0.6867, Validation Loss: 0.6390\n",
      "Learning Rate: 9.000000000000001e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 63/100 [05:30<03:10,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62: Train Loss: 0.6845, Validation Loss: 0.6321\n",
      "Learning Rate: 9.000000000000001e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 64/100 [05:36<03:10,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: Train Loss: 0.6837, Validation Loss: 0.6317\n",
      "Learning Rate: 9.000000000000001e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 65/100 [05:41<03:04,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64: Train Loss: 0.6804, Validation Loss: 0.6340\n",
      "Learning Rate: 9.000000000000001e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 66/100 [05:46<02:57,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65: Train Loss: 0.6934, Validation Loss: 0.6322\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 67/100 [05:51<02:51,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: Train Loss: 0.6783, Validation Loss: 0.6345\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 68/100 [05:57<02:47,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67: Train Loss: 0.6814, Validation Loss: 0.6399\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 69/100 [06:02<02:45,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: Train Loss: 0.6718, Validation Loss: 0.6308\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 70/100 [06:08<02:41,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69: Train Loss: 0.6910, Validation Loss: 0.6415\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 71/100 [06:13<02:37,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: Train Loss: 0.6845, Validation Loss: 0.6418\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 72/100 [06:19<02:32,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: Train Loss: 0.7038, Validation Loss: 0.6293\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 73/100 [06:24<02:25,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72: Train Loss: 0.7081, Validation Loss: 0.6323\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 74/100 [06:29<02:17,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: Train Loss: 0.6690, Validation Loss: 0.6335\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 75/100 [06:34<02:10,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74: Train Loss: 0.6866, Validation Loss: 0.6379\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 76/100 [06:39<02:04,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: Train Loss: 0.6926, Validation Loss: 0.6368\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 77/100 [06:44<01:58,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76: Train Loss: 0.6803, Validation Loss: 0.6361\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 78/100 [06:50<01:54,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77: Train Loss: 0.6675, Validation Loss: 0.6372\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 79/100 [06:55<01:49,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: Train Loss: 0.6796, Validation Loss: 0.6356\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 80/100 [07:00<01:43,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79: Train Loss: 0.6915, Validation Loss: 0.6337\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 81/100 [07:05<01:37,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80: Train Loss: 0.6748, Validation Loss: 0.6314\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 82/100 [07:10<01:33,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81: Train Loss: 0.6684, Validation Loss: 0.6323\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 83/100 [07:15<01:27,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82: Train Loss: 0.6679, Validation Loss: 0.6392\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 84/100 [07:20<01:21,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83: Train Loss: 0.6904, Validation Loss: 0.6381\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 85/100 [07:25<01:16,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84: Train Loss: 0.6825, Validation Loss: 0.6402\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 86/100 [07:30<01:11,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: Train Loss: 0.6806, Validation Loss: 0.6328\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 87/100 [07:35<01:06,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: Train Loss: 0.6721, Validation Loss: 0.6457\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 88/100 [07:41<01:00,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87: Train Loss: 0.6783, Validation Loss: 0.6380\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 89/100 [07:46<00:56,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88: Train Loss: 0.6941, Validation Loss: 0.6259\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 90/100 [07:51<00:51,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89: Train Loss: 0.6733, Validation Loss: 0.6346\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 91/100 [07:56<00:46,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90: Train Loss: 0.6995, Validation Loss: 0.6321\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 92/100 [08:01<00:41,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91: Train Loss: 0.6845, Validation Loss: 0.6313\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 93/100 [08:07<00:35,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: Train Loss: 0.6748, Validation Loss: 0.6361\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 94/100 [08:12<00:30,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93: Train Loss: 0.6708, Validation Loss: 0.6377\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 95/100 [08:17<00:25,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94: Train Loss: 0.6673, Validation Loss: 0.6355\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 96/100 [08:22<00:20,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95: Train Loss: 0.7034, Validation Loss: 0.6347\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 97/100 [08:27<00:15,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96: Train Loss: 0.6892, Validation Loss: 0.6321\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 98/100 [08:32<00:10,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97: Train Loss: 0.6650, Validation Loss: 0.6333\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 99/100 [08:37<00:05,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98: Train Loss: 0.6704, Validation Loss: 0.6303\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [08:42<00:00,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: Train Loss: 0.6640, Validation Loss: 0.6352\n",
      "Learning Rate: 9.000000000000001e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'wonderwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[109], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m optimizer\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLearning Rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mwonderwords\u001b[49m\u001b[38;5;241m.\u001b[39mRandomWord()\n\u001b[1;32m     49\u001b[0m MODEL_TAG \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;241m.\u001b[39mword(include_categories\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madjective\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;241m.\u001b[39mword()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wonderwords' is not defined"
     ]
    }
   ],
   "source": [
    "MODEL_TAG = \"\"\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "# Reset weights before training\n",
    "reset_weights()\n",
    "\n",
    "# Optimizer with modified learning rate\n",
    "optimizer = torch.optim.Adam(classifier.mods.classifier.parameters(), lr=0.0009)\n",
    "\n",
    "# Scheduler to reduce learning rate on plateau\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(100)):\n",
    "    # Set model to training mode\n",
    "    classifier.train()\n",
    "    losses = []\n",
    "    \n",
    "    for batch_idx, (X, y) in enumerate(train_dl):\n",
    "        logits, confidences, classes, decoded_classes = classifier(X)\n",
    "        loss = loss_fn(logits, y)\n",
    "        \n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        loss.backward()        # Backpropagate\n",
    "        optimizer.step()       # Update parameters\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    train_loss.append(np.mean(losses))\n",
    "\n",
    "    # Validation step\n",
    "    classifier.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient calculation for validation\n",
    "        val_preds, *_ = classifier(Xval)\n",
    "        val_loss_ = loss_fn(val_preds, yval)\n",
    "        val_loss.append(val_loss_.item())\n",
    "    \n",
    "    # Print loss\n",
    "    print(f\"Epoch {epoch}: Train Loss: {train_loss[-1]:.4f}, Validation Loss: {val_loss[-1]:.4f}\")\n",
    "\n",
    "    # Step the scheduler with the validation loss\n",
    "    scheduler.step(val_loss_)\n",
    "\n",
    "    # Optional: print the current learning rate\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(f\"Learning Rate: {param_group['lr']}\")\n",
    "r = wonderwords.RandomWord()\n",
    "MODEL_TAG = f'{r.word(include_categories=[\"adjective\"])}_{r.word()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9aabd246",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = wonderwords.RandomWord()\n",
    "MODEL_TAG = f'{r.word(include_categories=[\"adjective\"])}_{r.word()}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1ed48124-7fde-4c6c-93a4-41cd1fb56b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['train','val'])\n",
    "plt.title(MODEL_TAG)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35711b3-401c-4668-bbee-610fb0385998",
   "metadata": {},
   "source": [
    "### Validation accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "47c12d93-65b3-4594-9903-7f2a5b1a7f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['air', 'vac', 'off']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d0c5d6d1-998e-4c70-8e12-de4d5e60fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, *rest = classifier(Xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f4ffa15a-3cad-437b-bae0-a4cfd51b1470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 0, 1, 1, 2])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0df37bba-6218-498b-8e7e-4ea1e932cb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 0, 1, 1, 2])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yval.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "991325d5-fc70-4d4f-84a6-94b4ec8a1ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds.argmax(axis=1) == yval.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff356d-9e15-4e34-b764-c7e862ffb552",
   "metadata": {},
   "source": [
    "### Train accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "872d2a4c-113d-4302-bba0-e676120d1e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 2, 1, 2, 0, 1, 2, 0, 2, 1, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 0, 1, 2,\n",
       "        1, 0, 1, 2, 1, 2, 1, 2, 1, 1, 0, 2, 1, 2, 1, 2, 0, 1, 0, 1, 2, 1, 2, 0,\n",
       "        0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 2, 0, 0, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 0,\n",
       "        0, 1, 1, 0, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 2, 1, 1, 0, 2, 2, 2, 1,\n",
       "        0, 2, 0, 2, 2, 1, 2, 0, 1, 0, 1, 0, 0, 1, 2, 0, 0, 0, 2, 0, 2, 2, 0, 0,\n",
       "        2, 2, 1, 1, 1, 0, 1, 0, 2, 1, 1, 1, 0, 1, 0, 2, 1, 1, 2])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([cats.index(val) for val in ytrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6538e28f-09bd-48ed-92d8-3c8714aac3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 2, 1, 2, 0, 1, 2, 0, 2, 1, 2, 2, 2, 0, 0, 0, 2, 2, 0, 2, 0, 1, 2,\n",
       "        1, 0, 1, 2, 1, 2, 1, 2, 1, 1, 0, 2, 1, 2, 1, 2, 0, 1, 0, 1, 2, 1, 2, 0,\n",
       "        0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 2, 0, 0, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 0,\n",
       "        0, 1, 1, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 2, 1, 1, 0, 2, 2, 2, 1,\n",
       "        0, 2, 0, 2, 2, 1, 2, 0, 1, 0, 1, 0, 0, 1, 2, 0, 0, 0, 2, 0, 2, 2, 0, 0,\n",
       "        2, 2, 1, 1, 1, 0, 1, 0, 2, 1, 1, 1, 0, 1, 0, 2, 1, 1, 2])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds, *rest = classifier(Xtrain)\n",
    "train_preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "98f3075c-3c42-4103-86a1-509309309445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9856)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor([cats.index(val) for val in ytrain]) == train_preds.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662e8cf",
   "metadata": {},
   "source": [
    "# Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "741eb91d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xcvxcvytest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mxcvxcvytest\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xcvxcvytest' is not defined"
     ]
    }
   ],
   "source": [
    "xcvxcvytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca5ad0c-7686-4c2d-9bdd-ebe63bc1b2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4167)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([cats.index(val) for val in ytest])\n",
    "test_preds, *rest = classifier(Xtest)\n",
    "test_preds.argmax(axis=1)\n",
    "(torch.tensor([cats.index(val) for val in ytest]) == test_preds.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1776fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load new test data\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "path = Path(\"/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/g28_test\")\n",
    "files = list(path.rglob(\"*.wav\"))\n",
    "df_test = pd.DataFrame({\"filepath\":files})\n",
    "df_test[\"label\"] = df_test[\"filepath\"].apply(lambda x: Path(x).parent.name)\n",
    "df_test[\"duration\"] = df_test[\"filepath\"].apply(lambda x: librosa.get_duration(path=x))\n",
    "df_test[\"name\"] = df_test[\"filepath\"].apply(lambda x: Path(x).name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c5a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>/Users/jonas/Library/CloudStorage/OneDrive-Uni...</td>\n",
       "      <td>off</td>\n",
       "      <td>4.0</td>\n",
       "      <td>off_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/jonas/Library/CloudStorage/OneDrive-Uni...</td>\n",
       "      <td>air</td>\n",
       "      <td>4.0</td>\n",
       "      <td>air_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/Users/jonas/Library/CloudStorage/OneDrive-Uni...</td>\n",
       "      <td>vac</td>\n",
       "      <td>4.0</td>\n",
       "      <td>vac_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/Users/jonas/Library/CloudStorage/OneDrive-Uni...</td>\n",
       "      <td>vac</td>\n",
       "      <td>4.0</td>\n",
       "      <td>vac_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/Users/jonas/Library/CloudStorage/OneDrive-Uni...</td>\n",
       "      <td>vac</td>\n",
       "      <td>4.0</td>\n",
       "      <td>vac_3.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filepath label  duration  \\\n",
       "17  /Users/jonas/Library/CloudStorage/OneDrive-Uni...   off       4.0   \n",
       "3   /Users/jonas/Library/CloudStorage/OneDrive-Uni...   air       4.0   \n",
       "8   /Users/jonas/Library/CloudStorage/OneDrive-Uni...   vac       4.0   \n",
       "9   /Users/jonas/Library/CloudStorage/OneDrive-Uni...   vac       4.0   \n",
       "11  /Users/jonas/Library/CloudStorage/OneDrive-Uni...   vac       4.0   \n",
       "\n",
       "         name  \n",
       "17  off_3.wav  \n",
       "3   air_3.wav  \n",
       "8   vac_1.wav  \n",
       "9   vac_0.wav  \n",
       "11  vac_3.wav  "
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ab9504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop(df_test[(df_test.duration < 3.9)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb90603",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[~df_test.name.str.contains(\"_0.wav\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a1993",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = torch.stack([Transform.load_audio(fp) for fp in df_test.filepath])\n",
    "ytest = list(df_test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce19d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = ApplianceDS(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f80a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=len(test_ds), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4804267b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([cats.index(val) for val in ytest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459cbee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds, *rest = classifier(Xtest)\n",
    "test_preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c458bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = ApplianceDS(Xtrain, ytrain)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=len(test_ds), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a29bc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([cats.index(val) for val in ytest])\n",
    "test_preds, *rest = classifier(Xtest)\n",
    "test_preds.argmax(axis=1)\n",
    "(torch.tensor([cats.index(val) for val in ytest]) == test_preds.argmax(axis=1)).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11db49f8",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "15dec60a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier_name = str(path.name)\n",
    "model_path = path.parent.parent / \"models\"\n",
    "file_name = f\"{classifier_name}_{MODEL_TAG}.pt\"\n",
    "torch.save(classifier,f\"{model_path}/{file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4f95be15",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_json_name = f'{classifier_name}_cats.json'\n",
    "\n",
    "import json\n",
    "with open(cats_json_name, 'w') as f:\n",
    "    json.dump(cats, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7642190a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/jonas/Library/CloudStorage/OneDrive-UniversityofExeter/sound_recognition/data')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c88639b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'users/g28_huawei/g28_huawei_afraid_correspondence.pt' has been uploaded to bucket 'data_labear'.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "def upload_file_if_not_exists(bucket_name, folder_name, source_file_path, destination_file_name):\n",
    "    \"\"\"\n",
    "    Upload a file to Google Cloud Storage only if it does not exist in the specified folder.\n",
    "    \n",
    "    Args:\n",
    "        bucket_name (str): The name of the GCS bucket.\n",
    "        folder_name (str): The GCS folder name where the file will be uploaded.\n",
    "        source_file_path (str): The path to the local file.\n",
    "        destination_file_name (str): The name of the file in GCS.\n",
    "\n",
    "    Returns:\n",
    "        str: Message indicating whether the file was uploaded or already exists.\n",
    "    \"\"\"\n",
    "    # Initialize the Google Cloud Storage client\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Get the GCS bucket\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    # Create the full GCS path (including the folder and file name)\n",
    "    gcs_file_path = os.path.join(folder_name, destination_file_name)\n",
    "\n",
    "    # Check if the file already exists in GCS\n",
    "    blob = bucket.blob(gcs_file_path)\n",
    "\n",
    "    if blob.exists():\n",
    "        return f\"File '{gcs_file_path}' already exists in bucket '{bucket_name}'.\"\n",
    "\n",
    "    # Upload the file if it doesn't exist\n",
    "    blob.upload_from_filename(source_file_path)\n",
    "    return f\"File '{gcs_file_path}' has been uploaded to bucket '{bucket_name}'.\"\n",
    "\n",
    "# Example usage\n",
    "bucket_name = \"data_labear\"\n",
    "folder_name = f\"users/{path.name}\"  # Leave empty if there's no folder\n",
    "source_file_path = str(model_path / file_name)\n",
    "destination_file_name = file_name\n",
    "\n",
    "result = upload_file_if_not_exists(bucket_name, folder_name, source_file_path, destination_file_name)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "030c773f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g28_huawei'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
